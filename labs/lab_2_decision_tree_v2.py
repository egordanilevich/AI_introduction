# -*- coding: utf-8 -*-
"""Lab_2_Decision_tree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ay5HOsQkebpSvUdEpPTi0tgAeLuDeHGr

### Лабораторная работа № 2 "Ансамбли моделей на примере решающих деревьев"

https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier


df = pd.read_csv('heart.csv')

df

"""**1.** Разбить выборку на две части (train, test)"""

# Разделение на обучающий и тестовый наборы (пополам)
X = df.drop('target', axis=1)
Y = df['target']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=3)

print("Обучающая выборка:", X_train.shape)
print("Тестовой выборка:", X_test.shape)

"""**2.** С помощью простого решающего дерева (см. класс sklearn.tree.DecisionTreeClassifier()). Обучить модель, не задавая ограничения на глубину решающего дерева, оценить точность обучения и тестирования (здесь в качестве точности использовать долю верных ответов). Сравнить точность на обучающей и тестовой выборке, что можно сказать о модели?"""

# Создаем объект простого решающего дерева
clf = DecisionTreeClassifier(random_state=3)

# Обучаем модель на обучающих данных
clf.fit(X_train, Y_train)

# Предсказываем значения для обучающей и тестовой выборок
train_preds = clf.predict(X_train)
test_preds = clf.predict(X_test)

# Оцениваем точность модели на обучающей и тестовой выборках
train_accuracy = accuracy_score(Y_train, train_preds)
test_accuracy = accuracy_score(Y_test, test_preds)

print(f"Точность на обучающей выборке: {train_accuracy}")
print(f"Точность на тестовой выборке: {test_accuracy}")

"""*   Тк не задано органичение глубины дерева, модель могла настроиться на максимальную глубину
*   Теоритически это могло вызвать переобучение
*   На тренировочной выборке точность 100%, что похоже на переобучение
*   На тестовой выборке также имеется неплохая точность, модель можно считать достоверной

**3.** C помощью класса sklearn.model_selection.GridSearchCV() выполнить оптимизацию решающего дерева по гиперпараметрам:
* 'max_depth': [3,4,5,6,7,8,9,10,None],
* 'max_features':  ['sqrt', 'log2', None],
* 'min_samples_leaf': range(1,10),
* 'min_samples_split': range(2, 10)

Гиперпараметры можно представить в виде словаря и передать их в качестве параметра param_grid при создании экземпляра класса GridSearchCV(). В качестве scoring задать 'accuracy', количество фолдов (параметр cv) задать равным 5.

**3.1** Вывести оптимальные параметры модели и ее точность (смотрите среди перечня атрубутов класса)
"""

# 3
# Создаем объект простого решающего дерева
clf_opt = DecisionTreeClassifier(random_state=3)

# Задаем словарь гиперпараметров для оптимизации
grid_params = {
    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, None], #Глубина дерева
    'max_features': ['sqrt', 'log2', None], #количество признаков, которые следует учитывать при поиске лучшего разделения.
    'min_samples_leaf': range(1, 10),  #Минимальное количество образцов в узле
    'min_samples_split': range(2, 10) #Минимальное количесво образцов для разделения в узле
}

# Создаем объект GridSearchCV для подбора оптимальных параметров
grid_search = GridSearchCV(estimator=clf_opt, param_grid = grid_params, scoring='accuracy', cv=5)

# Выполняем поиск оптимальных гиперпараметров на обучающих данных
grid_search.fit(X_train, Y_train)

# Получаем лучшие гиперпараметры и лучшую оценку точности
best_params = grid_search.best_params_
best_score = grid_search.best_score_

#3.1
print("Лучшие гиперпараметры:", best_params)
print("Лучшая оценка точности:", best_score)

"""**4.** Обучите новое дерево, задавая оптимальные параметры, полученные в п.3. Оцените точность на обучающей и тестовой выборкой, сравните их с точностью первой модели. Как изменилось качество модели?"""

# Создаем новый объект классификатора с оптимальными параметрами
optimal_clf = DecisionTreeClassifier(random_state=3, **best_params)

# Обучаем новое дерево на обучающих данных
optimal_clf.fit(X_train, Y_train)

# Предсказываем значения для обучающей и тестовой выборок
train_preds_optimal = optimal_clf.predict(X_train)
test_preds_optimal = optimal_clf.predict(X_test)

# Оцениваем точность новой модели на обучающей и тестовой выборках
train_accuracy_optimal = accuracy_score(Y_train, train_preds_optimal)
test_accuracy_optimal = accuracy_score(Y_test, test_preds_optimal)
print("")
print("Оптимальная модель:")

print("Точность новой модели на обучающей выборке:", train_accuracy_optimal)
print("Точность новой модели на тестовой выборке:", test_accuracy_optimal)

# Сравниваем с точностью первой модели
print("")
print("Исходная модель:")

print("Точность на обучающей выборке:", train_accuracy)
print("Точность на тестовой выборке:", test_accuracy)

"""**5.** Визуализируйте полученное дерево решений"""

# Визуализируем дерево решений
plt.figure(figsize=(15, 8))
plot_tree(optimal_clf, filled=True, feature_names=X_train.columns.tolist(), class_names=['0', '1'], max_depth=2)
plt.show()

"""**7.** На основе процедуры бэггинга обучить композицию решающих деревьев, провести оптимизацию модели по гиперпараметру - кол-во деревьев в ансамбле. Использовать классы BaggingClassifier() и GridSearchCV(). Определить оптимальное кол-во деревьев и оценить точность модели."""

import warnings
warnings.filterwarnings("ignore")

# Создаем базовую модель решающего дерева
base_model = DecisionTreeClassifier(random_state=3)

# Создаем объект BaggingClassifier
bagging_clf = BaggingClassifier(base_model, random_state=3)

# Задаем параметры для оптимизации
param_grid_bagging = {
    'n_estimators': [25, 50, 100, 150, 200, 250, 300, 350],  # количество деревьев
    'max_samples': [0.4, 0.5, 0.7, 0.9, 1.0],  # доля выборки для обучения каждого дерева
}

# Создаем объект GridSearchCV
grid_search_bagging = GridSearchCV(estimator=bagging_clf, param_grid=param_grid_bagging, scoring='accuracy', cv=5)

# Выполняем поиск оптимального количества деревьев на обучающих данных
grid_search_bagging.fit(X_train, Y_train)

# Получаем лучшие параметры и точность модели
best_params_bagging = grid_search_bagging.best_params_
best_score_bagging = grid_search_bagging.best_score_

# Оценка модели на тестовых данных
test_accuracy_bagging = grid_search_bagging.score(X_test, Y_test)

# Вывод результатов
print(f"Лучшие параметры для BaggingClassifier: {best_params_bagging}")
print(f"Точность на обучающей выборке: {best_score_bagging}")
print(f"Точность на тестовой выборке: {test_accuracy_bagging}")

"""**8.** Построить ансамбль решающих деревьев в виде случайного леса (см. класс sklearn.ensemble.RandomForestClassifier()), провести оптимизацию модели по гиперпараметрам: 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'bootstrap', 'max_features'"""

# Создаем объект случайного леса
rf_clf = RandomForestClassifier(random_state=3)

param_grid_rf = {
    'n_estimators': [50, 100, 150, 200, 250],  # Количество деревьев в лесу
    'max_depth': [None, 5, 10, 15, 20],  # Максимальная глубина деревьев
    'min_samples_split': [2, 5, 10],  # Минимальное количество образцов для разделения узла
    'min_samples_leaf': [1, 2, 4],  # Минимальное количество образцов в листовом узле
    'bootstrap': [True, False],  # Использование бутстрепа для обучения деревьев
    'max_features': ['sqrt', 'log2', None],  # Количество признаков для выбора при разбиении
    'criterion': ['gini', 'entropy'],  # Критерий для оценки качества разбиения
    'max_samples': [None, 0.5, 0.7, 0.9],  # Максимальное количество образцов для обучения каждого дерева
    'min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3],  # Минимальная взвешенная доля образцов в листе
    'class_weight': [None, 'balanced'],  # Веса классов
    #'warm_start': [False, True],  # Повторное использование ранее выученной модели
    #'oob_score': [False, True]  # Использование out-of-bag (oob) образцов для оценки обобщающей способности
}


# Создаем объект GridSearchCV
grid_search_rf = GridSearchCV(estimator=rf_clf, param_grid=param_grid_rf, scoring='accuracy', cv=5, n_jobs=-1)

# Выполняем поиск оптимальных гиперпараметров на обучающих данных
grid_search_rf.fit(X_train, Y_train)

# Получаем лучшие параметры и точность модели
best_params_rf = grid_search_rf.best_params_
best_score_rf = grid_search_rf.best_score_

# Оценка модели на тестовых данных
test_accuracy_rf = grid_search_rf.score(X_test, Y_test)

# Вывод результатов
print(f"Лучшие параметры для RandomForestClassifier: {best_params_rf}")
print(f"Точность на обучающей выборке: {best_score_rf}")
print(f"Точность на тестовой выборке: {test_accuracy_rf}")

"""**9.** Для всех моделей рассчитать метрики качества (accuracy, precision, recall, F1-score) на тестовой выборке. результат представить в виде датафрейма (например явняе индексы строк - вид модели, столбцы - вид метрики)"""

# Определение функции для расчета метрик
def calculate_metrics(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    return accuracy, precision, recall, f1

# Расчет метрик для каждой модели
models = {
    "Decision Tree": clf,
    "Optimal Decision Tree": optimal_clf,
    "Bagging Classifier": grid_search_bagging,
    "Random Forest Classifier": grid_search_rf
}

results = {}
for name, model in models.items():
    y_pred = model.predict(X_test)
    results[name] = calculate_metrics(Y_test, y_pred)

# Создание датафрейма для результатов
metrics_df = pd.DataFrame(results, index=["Accuracy", "Precision", "Recall", "F1-score"]).T
print(metrics_df)

"""Decision Tree: Эта модель показывает хороший уровень точности (Accuracy) в районе 92.59%, что свидетельствует о том, что более простая модель без оптимизации гиперпараметров может давать довольно неплохие результаты. Однако, полнота (Recall) и F1-мера несколько ниже по сравнению с другими моделями, что может говорить о недостаточной способности модели идентифицировать положительные случаи.

Optimal Decision Tree: После оптимизации гиперпараметров этот классификатор показывает значительное улучшение во всех метриках качества по сравнению с базовым решающим деревом. Точность (Accuracy) выросла до 96.30%, а значения Precision, Recall и F1-мера также значительно улучшились. Это свидетельствует о том, что оптимизация гиперпараметров может существенно повысить эффективность модели.

Bagging Classifier: Этот метод ансамблирования демонстрирует хорошие результаты с точностью в 93.96%. Он обладает хорошим балансом между Precision и Recall, что отражается в F1-мере. Это говорит о том, что использование бэггинга помогает улучшить обобщающую способность модели и сделать ее более стабильной.

Random Forest Classifier: Эта модель демонстрирует наивысшие результаты среди всех рассмотренных. С точностью в 96.88% она превосходит другие модели по всем метрикам качества. Особенно важно отметить высокие значения Recall и F1-меры, что указывает на высокую способность модели правильно идентифицировать положительные случаи и сохранять баланс между Precision и Recall.

Таким образом, на основе анализа результатов метрик качества на тестовой выборке, можно сделать вывод о том, что Random Forest Classifier является наиболее оптимальной моделью.
"""